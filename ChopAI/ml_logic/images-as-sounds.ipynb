{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get output as midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Music imports\n",
    "from music21 import instrument, note, chord, stream\n",
    "from PIL import Image, ImageOps\n",
    "import mido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From arrays to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to use as key to sort images in music piece order\n",
    "def get_alphabetical_numerical_sequences(x):\n",
    "    \"\"\"\n",
    "    Returns number of a file within a given folder\n",
    "    E.g.: returns 18 for file 'ballade2_instrument_0_18'\n",
    "    \"\"\"\n",
    "    x = x.split('.')[0]\n",
    "    parts = x.split('_')\n",
    "    numerical = int((parts[-1]))\n",
    "    return numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "get_alphabetical_numerical_sequences('ballade2_instrument_0_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data_image/ballade2/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating a list of image names for one music piece (ballade2)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m image_list \u001b[39m=\u001b[39m [image \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m../../data_image/ballade2/\u001b[39;49m\u001b[39m'\u001b[39;49m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m image_list\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data_image/ballade2/'"
     ]
    }
   ],
   "source": [
    "# Creating a list of image names for one music piece (ballade2)\n",
    "image_list = [image for image in os.listdir('../../data_image/ballade2/')]\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ballade2_instrument_0_0.png',\n",
       " 'ballade2_instrument_0_1.png',\n",
       " 'ballade2_instrument_0_2.png',\n",
       " 'ballade2_instrument_0_3.png',\n",
       " 'ballade2_instrument_0_4.png',\n",
       " 'ballade2_instrument_0_5.png',\n",
       " 'ballade2_instrument_0_6.png',\n",
       " 'ballade2_instrument_0_7.png',\n",
       " 'ballade2_instrument_0_8.png',\n",
       " 'ballade2_instrument_0_9.png',\n",
       " 'ballade2_instrument_0_10.png',\n",
       " 'ballade2_instrument_0_11.png',\n",
       " 'ballade2_instrument_0_12.png',\n",
       " 'ballade2_instrument_0_13.png',\n",
       " 'ballade2_instrument_0_14.png',\n",
       " 'ballade2_instrument_0_15.png',\n",
       " 'ballade2_instrument_0_16.png',\n",
       " 'ballade2_instrument_0_17.png',\n",
       " 'ballade2_instrument_0_18.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the images in order for one music piece (ballade2)\n",
    "image_list = sorted(image_list, key = lambda x : get_alphabetical_numerical_sequences(x))\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Transforming all images into arrays and adding them into a list\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m array_list \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m image_list: \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     array \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mimread(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../data_image/ballade2/\u001b[39m\u001b[39m{\u001b[39;00mimage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     array_list\u001b[39m.\u001b[39mappend(array)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Transforming all images into arrays and adding them into a list\n",
    "array_list = []\n",
    "for image in image_list: \n",
    "    array = plt.imread(f\"../../data_image/ballade2/{image}\")\n",
    "    array_list.append(array)\n",
    "    \n",
    "array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Concatenating all arrays into one\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m array_conc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(array_list, axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m array_conc\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# Concatenating all arrays into one\n",
    "array_conc = np.concatenate(array_list, axis = 1)\n",
    "array_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to create and save an array from an image\n",
    "def array_to_image(array, output_file_path):\n",
    "    \"\"\"\n",
    "    Save a numpy array of dimension 106 x 100 as a midi image into the corresponding subfolder\n",
    "    'music_piece' of the 'data_output_image' folder\n",
    "    \"\"\"\n",
    "    plt.imsave(output_file_path, array, cmap='gray')\n",
    "    \n",
    "# Question: should we add the transpose step here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_conc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Using the function for one music piece\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m array_to_image(array_conc,\u001b[39m\"\u001b[39m\u001b[39m../../data_output_image/ballade2/image_conc.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array_conc' is not defined"
     ]
    }
   ],
   "source": [
    "# Using the function for one music piece\n",
    "array_to_image(array_conc,\"../../data_output_image/ballade2/image_conc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From images to midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column2notes(column, lowerBoundNote = 21):\n",
    "    notes = []\n",
    "    for i in range(len(column)):\n",
    "        if column[i] > 255/2:\n",
    "            notes.append(i+lowerBoundNote)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNotes(newNotes, prevNotes, resolution = 0.25): \n",
    "    res = {} \n",
    "    for note in newNotes:\n",
    "        if note in prevNotes:\n",
    "            res[note] = prevNotes[note] + resolution\n",
    "        else:\n",
    "            res[note] = resolution\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2midi(image_path, lowerBoundNote = 21, resolution = 0.25):\n",
    "    \"\"\"\n",
    "    From an existing image:\n",
    "        - Convert to note\n",
    "        - Save result as a midi file in the subfolder 'music_piece_name' of the 'data_output_sound' folder \n",
    "    \"\"\"\n",
    "    \n",
    "    output_folder = f\"../../data_output_midi/{image_path.split('/')[-2]}\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    output_filename = os.path.join(output_folder, image_path.split(\"/\")[-1].replace(\".png\",\".mid\"))\n",
    "    print(output_filename)\n",
    "    \n",
    "    with ImageOps.grayscale(Image.open(image_path)) as image:\n",
    "        im_arr = np.frombuffer(image.tobytes(), dtype=np.uint8)\n",
    "        print(im_arr.shape)\n",
    "        try:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0]))\n",
    "        except:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0],3))\n",
    "            im_arr = np.dot(im_arr, [0.33, 0.33, 0.33])\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "\n",
    "    prev_notes = updateNotes(im_arr.T[0,:],{}, resolution = resolution)\n",
    "    for column in im_arr.T[1:,:]:\n",
    "        notes = column2notes(column, lowerBoundNote=lowerBoundNote)\n",
    "        # pattern is a chord\n",
    "        notes_in_chord = notes\n",
    "        old_notes = prev_notes.keys()\n",
    "        for old_note in old_notes:\n",
    "            if not old_note in notes_in_chord:\n",
    "                new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if offset - prev_notes[old_note] >= 0:\n",
    "                    new_note.offset = offset - prev_notes[old_note]\n",
    "                    output_notes.append(new_note)\n",
    "                elif offset == 0:\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)                    \n",
    "                else:\n",
    "                    print(offset,prev_notes[old_note],old_note)\n",
    "\n",
    "        prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += resolution\n",
    "\n",
    "    for old_note in prev_notes.keys():\n",
    "        new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        new_note.offset = offset - prev_notes[old_note]\n",
    "\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    midi_stream.write('midi', fp=output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_output_midi/ballade2/image_conc.mid\n",
      "(201400,)\n"
     ]
    }
   ],
   "source": [
    "# Testing the function on concatenated array\n",
    "image_path = \"../../data_output_image/ballade2/image_conc.png\"\n",
    "image2midi(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating resolution impact on tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imwrite\n",
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "\n",
    "def extractNote(element):\n",
    "    return int(element.pitch.ps)\n",
    "\n",
    "#################################\n",
    "\n",
    "def extractDuration(element):\n",
    "    return element.duration.quarterLength\n",
    "\n",
    "#################################\n",
    "\n",
    "def get_notes(notes_to_parse):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all the notes and chords from the midi files into a dictionary containing:\n",
    "        - Start: unit time at which the note starts playing\n",
    "        - Pitch: pitch of the note\n",
    "        - Duration: number of time units the note is played for\n",
    "    \"\"\"\n",
    "    durations = []\n",
    "    notes = []\n",
    "    start = []\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "\n",
    "            start.append(element.offset)\n",
    "            notes.append(extractNote(element))\n",
    "            durations.append(extractDuration(element))\n",
    "\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "            for chord_note in element:\n",
    "                start.append(element.offset)\n",
    "                durations.append(extractDuration(element))\n",
    "                notes.append(extractNote(chord_note))\n",
    "\n",
    "    return {\"start\":start, \"pitch\":notes, \"dur\":durations}\n",
    "\n",
    "#################################\n",
    "\n",
    "def midi2image(midi_path, max_repetitions = float(\"inf\"), resolution = 0.25, lowerBoundNote = 21, upperBoundNote = 127, maxSongLength = 100):\n",
    "\n",
    "    \"\"\"\n",
    "    1) Transform a midi file into a set of images:\n",
    "        - Each image has a size of 106 (all notes between lowerBound and upperBound) x 100 time units (maxSongLength)\n",
    "        - One time unit corresponds to 0.25 (resolution) beat from the original music\n",
    "    2) Store images into the corresponding sub-folder (identified by music piece name) of the 'data_image' folder\n",
    "    \"\"\"\n",
    "\n",
    "    output_folder = f\"data_image/{midi_path.split('/')[-1].replace('.mid', '')}\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    mid = converter.parse(midi_path)\n",
    "\n",
    "    instruments = instrument.partitionByInstrument(mid)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    try:\n",
    "        i=0\n",
    "        for instrument_i in instruments.parts:\n",
    "            notes_to_parse = instrument_i.recurse()\n",
    "\n",
    "            notes_data = get_notes(notes_to_parse)\n",
    "            if len(notes_data[\"start\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            if instrument_i.partName is None:\n",
    "                data[\"instrument_{}\".format(i)] = notes_data\n",
    "                i+=1\n",
    "            else:\n",
    "                data[instrument_i.partName] = notes_data\n",
    "\n",
    "    except:\n",
    "        notes_to_parse = mid.flat.notes\n",
    "        data[\"instrument_0\"] = get_notes(notes_to_parse)\n",
    "\n",
    "    for instrument_name, values in data.items():\n",
    "\n",
    "        pitches = values[\"pitch\"]\n",
    "        durs = values[\"dur\"]\n",
    "        starts = values[\"start\"]\n",
    "\n",
    "        index = 0\n",
    "        while index < max_repetitions:\n",
    "            matrix = np.zeros((upperBoundNote-lowerBoundNote,maxSongLength))\n",
    "\n",
    "\n",
    "            for dur, start, pitch in zip(durs, starts, pitches):\n",
    "                dur = int(dur/resolution)\n",
    "                start = int(start/resolution)\n",
    "\n",
    "                if not start > index*(maxSongLength+1) or not dur+start < index*maxSongLength:\n",
    "                    for j in range(start,start+dur):\n",
    "                        if j - index*maxSongLength >= 0 and j - index*maxSongLength < maxSongLength:\n",
    "                            matrix[pitch-lowerBoundNote,j - index*maxSongLength] = 255\n",
    "\n",
    "            # if matrix.any(): # If matrix contains no notes (only zeros) don't save it\n",
    "            output_filename = os.path.join(output_folder, midi_path.split('/')[-1].replace(\".mid\",f\"_{instrument_name}_{index}.png\"))\n",
    "            imwrite(output_filename,matrix.astype(np.uint8))\n",
    "            index += 1\n",
    "            # else:\n",
    "                # break\n",
    "\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m midi_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../../data_raw/ballade2.mid\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m midi2image(midi_path)\n",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb Cell 20\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mfor\u001b[39;00m dur, start, pitch \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(durs, starts, pitches):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m     dur \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(dur\u001b[39m/\u001b[39mresolution)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m     start \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(start\u001b[39m/\u001b[39;49mresolution)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m start \u001b[39m>\u001b[39m index\u001b[39m*\u001b[39m(maxSongLength\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m dur\u001b[39m+\u001b[39mstart \u001b[39m<\u001b[39m index\u001b[39m*\u001b[39mmaxSongLength:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/images-as-sounds.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start,start\u001b[39m+\u001b[39mdur):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "midi_path = '../../data_raw/ballade2.mid'\n",
    "midi2image(midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..', '..', 'data_raw', 'ballade2.mid']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
