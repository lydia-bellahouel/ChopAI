{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full data preprocessing for C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Music and image imports\n",
    "from imageio import imwrite\n",
    "from music21 import converter, instrument, note, chord, converter\n",
    "from PIL import Image, ImageOps\n",
    "import mido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting midi file to images and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From midi file to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediary function\n",
    "def extractNote(element):\n",
    "    return int(element.pitch.ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediary function\n",
    "def extractDuration(element):\n",
    "    return element.duration.quarterLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediary function\n",
    "def get_notes(notes_to_parse):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all the notes and chords from the midi files into a dictionary containing:\n",
    "        - Start: unit time at which the note starts playing\n",
    "        - Pitch: pitch of the note\n",
    "        - Duration: number of time units the note is played for\n",
    "    \"\"\"\n",
    "    durations = []\n",
    "    notes = []\n",
    "    start = []\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "\n",
    "            start.append(element.offset)\n",
    "            notes.append(extractNote(element))\n",
    "            durations.append(extractDuration(element))\n",
    "\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "            for chord_note in element:\n",
    "                start.append(element.offset)\n",
    "                durations.append(extractDuration(element))\n",
    "                notes.append(extractNote(chord_note))\n",
    "\n",
    "    return {\"start\":start, \"pitch\":notes, \"dur\":durations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi2image(midi_path, output_folder_path, max_repetitions = float(\"inf\"), resolution = 0.25, lowerBoundNote = 21, upperBoundNote = 127, maxSongLength = 100):\n",
    "\n",
    "    \"\"\"\n",
    "    1) Transform a midi file into a set of images:\n",
    "        - Each image has a size of 106 (all notes between lowerBound and upperBound) x 106 time units (maxSongLength)\n",
    "        - One time unit corresponds to 0.25 (resolution) beat from the original music\n",
    "    2) Store images into the corresponding sub-folder (identified by music piece name) of the 'output_folder_path' folder\n",
    "    \"\"\"\n",
    "\n",
    "    output_folder = f\"{output_folder_path}{midi_path.split('/')[-1].replace('.mid', '')}\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    mid = converter.parse(midi_path)\n",
    "\n",
    "    instruments = instrument.partitionByInstrument(mid)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    try:\n",
    "        i=0\n",
    "        for instrument_i in instruments.parts:\n",
    "            notes_to_parse = instrument_i.recurse()\n",
    "\n",
    "            notes_data = get_notes(notes_to_parse)\n",
    "            if len(notes_data[\"start\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            if instrument_i.partName is None:\n",
    "                data[\"instrument_{}\".format(i)] = notes_data\n",
    "                i+=1\n",
    "            else:\n",
    "                data[instrument_i.partName] = notes_data\n",
    "\n",
    "    except:\n",
    "        notes_to_parse = mid.flat.notes\n",
    "        data[\"instrument_0\"] = get_notes(notes_to_parse)\n",
    "\n",
    "    for instrument_name, values in data.items():\n",
    "\n",
    "        pitches = values[\"pitch\"]\n",
    "        durs = values[\"dur\"]\n",
    "        starts = values[\"start\"]\n",
    "\n",
    "        index = 0\n",
    "        while index < max_repetitions:\n",
    "            matrix = np.zeros((upperBoundNote-lowerBoundNote,maxSongLength))\n",
    "\n",
    "\n",
    "            for dur, start, pitch in zip(durs, starts, pitches):\n",
    "                dur = int(dur/resolution)\n",
    "                start = int(start/resolution)\n",
    "\n",
    "                if not start > index*(maxSongLength+1) or not dur+start < index*maxSongLength:\n",
    "                    for j in range(start,start+dur):\n",
    "                        if j - index*maxSongLength >= 0 and j - index*maxSongLength < maxSongLength:\n",
    "                            matrix[pitch-lowerBoundNote,j - index*maxSongLength] = 255\n",
    "\n",
    "            if matrix.any(): # If matrix contains no notes (only zeros) don't save it\n",
    "                output_filename = os.path.join(output_folder, midi_path.split('/')[-1].replace(\".mid\",f\"_{instrument_name}_{index}.png\"))\n",
    "                imwrite(output_filename,matrix.astype(np.uint8))\n",
    "                index += 1\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "midi2image('../../data_test/Input_midi/ballade2.mid', '../../data_test/Input_image/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From image to midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediary function\n",
    "def column2notes(column, lowerBoundNote = 21):\n",
    "    notes = []\n",
    "    for i in range(len(column)):\n",
    "        if column[i] > 255/2:\n",
    "            notes.append(i+lowerBoundNote)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediary function\n",
    "def updateNotes(newNotes, prevNotes, resolution = 0.25): \n",
    "    res = {} \n",
    "    for note in newNotes:\n",
    "        if note in prevNotes:\n",
    "            res[note] = prevNotes[note] + resolution\n",
    "        else:\n",
    "            res[note] = resolution\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2midi(image_path, lowerBoundNote = 21, resolution = 0.25):\n",
    "    \"\"\"\n",
    "    From an existing image:\n",
    "        - Convert to notes\n",
    "        - Save result as a midi file in the subfolder 'music_piece_name' of the 'data_output_sound' folder \n",
    "    \"\"\"\n",
    "    \n",
    "    output_folder = f\"../../data_output_midi/{image_path.split('/')[-2]}\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    output_filename = os.path.join(output_folder, image_path.split(\"/\")[-1].replace(\".png\",\".mid\"))\n",
    "    print(output_filename)\n",
    "    \n",
    "    with ImageOps.grayscale(Image.open(image_path)) as image:\n",
    "        im_arr = np.frombuffer(image.tobytes(), dtype=np.uint8)\n",
    "        print(im_arr.shape)\n",
    "        try:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0]))\n",
    "        except:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0],3))\n",
    "            im_arr = np.dot(im_arr, [0.33, 0.33, 0.33])\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "\n",
    "    prev_notes = updateNotes(im_arr.T[0,:],{}, resolution = resolution)\n",
    "    for column in im_arr.T[1:,:]:\n",
    "        notes = column2notes(column, lowerBoundNote=lowerBoundNote)\n",
    "        # pattern is a chord\n",
    "        notes_in_chord = notes\n",
    "        old_notes = prev_notes.keys()\n",
    "        for old_note in old_notes:\n",
    "            if not old_note in notes_in_chord:\n",
    "                new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if offset - prev_notes[old_note] >= 0:\n",
    "                    new_note.offset = offset - prev_notes[old_note]\n",
    "                    output_notes.append(new_note)\n",
    "                elif offset == 0:\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)                    \n",
    "                else:\n",
    "                    print(offset,prev_notes[old_note],old_note)\n",
    "\n",
    "        prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += resolution\n",
    "\n",
    "    for old_note in prev_notes.keys():\n",
    "        new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        new_note.offset = offset - prev_notes[old_note]\n",
    "\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    midi_stream.write('midi', fp=output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_output_midi/data_raw/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ImageOps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Testing the function\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../../ChopAI/data_raw/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m image2midi(image_path)\n",
      "\u001b[1;32m/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m output_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, image_path\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m.mid\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(output_filename)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m ImageOps\u001b[39m.\u001b[39mgrayscale(Image\u001b[39m.\u001b[39mopen(image_path)) \u001b[39mas\u001b[39;00m image:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     im_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(image\u001b[39m.\u001b[39mtobytes(), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/agatheduranton/code/AgatheDuranton/ChopAI/ChopAI/ml_logic/full-data-preprocessing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(im_arr\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageOps' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing the function\n",
    "image_path = \"../../ChopAI/data_raw/\"\n",
    "image2midi(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data set and converting dataset to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_midi_data_as_images(midi_path, output_folder_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Iterate on all midi files from the 'midi_path' folder to:\n",
    "        - Keep music pieces with one piano only\n",
    "        - Store all corresponding images into a 'music_piece' subfolder of the \n",
    "    \"\"\"\n",
    "    # Storing all midi files into a 'files_raw' list\n",
    "    files_raw = [file for file in os.listdir(midi_path)]\n",
    "\n",
    "    # Storing all midi files with only one piano in a 'files' list\n",
    "    files = []\n",
    "    for file in files_raw:\n",
    "        try:\n",
    "            mid = converter.parse(f'{midi_path}/{file}')\n",
    "            file_instruments = instrument.partitionByInstrument(mid)\n",
    "            if len(file_instruments)==1:\n",
    "                files.append(file)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Iterating on all files from 'files' list to create images\n",
    "    for file in files:\n",
    "        file_path = f\"{midi_path}/{file}\"\n",
    "        midi2image(file_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(image_path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChopAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
