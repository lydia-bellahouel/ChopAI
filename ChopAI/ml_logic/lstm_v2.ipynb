{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import pickle\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Music\n",
    "import music21 as m21\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a train set ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data_raw/\"\n",
    "\n",
    "# Define the percentage of data to use to training the modle \n",
    "train_percentage = 90  \n",
    "\n",
    "\n",
    "train_dir = \"../../data_split/train/\"\n",
    "test_dir = \"../../data_split/test/\"\n",
    "\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "all_files = os.listdir(source_dir)\n",
    "\n",
    "num_train_files = int(len(all_files) * (train_percentage / 100))\n",
    "\n",
    "\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# Split the files into training and testing sets\n",
    "train_files = all_files[:num_train_files]\n",
    "test_files = all_files[num_train_files:]\n",
    "\n",
    "\n",
    "for file in train_files:\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    destination_file = os.path.join(train_dir, file)\n",
    "    shutil.copy(source_file, destination_file)\n",
    "\n",
    "\n",
    "for file in test_files:\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    destination_file = os.path.join(test_dir, file)\n",
    "    shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the vocabulary ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_into_notes():\n",
    "    # Extracted notes for each file\n",
    "    notes = []\n",
    "\n",
    "    # Save the indexes in notes in which a new composition started to create consistent sequences\n",
    "    new_composition_indexes = []\n",
    "\n",
    "    # Load THE !!TRAINING!! MIDI files to create the vocabulary\n",
    "    input_path = \"../../data_split/test\"\n",
    "    for file in os.listdir(input_path):\n",
    "        file_path = os.path.join(input_path, file)\n",
    "        \n",
    "        # Add new index to alert that it's a new composition\n",
    "        if new_composition_indexes and new_composition_indexes[-1] != len(notes):\n",
    "            new_composition_indexes.append(len(notes))\n",
    "\n",
    "        try:\n",
    "            # Convert the music into a score object\n",
    "            score = converter.parse(file_path)\n",
    "\n",
    "            print(\"Parsing %s\" % file)\n",
    "\n",
    "            elements_in_part = None\n",
    "\n",
    "            try:  # File has instrument parts\n",
    "                # Given a score that represents the MIDI, partition it into parts for each unique instrument found\n",
    "                partitions_by_instrument = instrument.partitionByInstrument(score)\n",
    "                # Visit all the elements (notes, chords, rests, and more) of each of its internal \"measures.\"\n",
    "                elements_in_part = partitions_by_instrument.parts[0].recurse()\n",
    "\n",
    "            except:  # File has notes in a flat structure\n",
    "                elements_in_part = score.flat.notes\n",
    "\n",
    "            # Scroll through all the elements (notes or chords) picked up\n",
    "            for element in elements_in_part:\n",
    "                # If the element is a note...\n",
    "                if isinstance(element, note.Note):\n",
    "                    # Add note to array\n",
    "                    notes.append(str(element.pitch))\n",
    "                # If the element is a chord (a set of notes --> e.g., C4 F4)\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    # Extract each note from the chord and insert it into the array in the format Note1.Note2.Note3\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"✅Loading training done\")\n",
    "\n",
    "    # Save the 'notes' list to a pickle file\n",
    "    os.makedirs(\"../../data_vocab/\")\n",
    "    with open(\"../../data_vocab/notes.pkl\", \"wb\") as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    # Return notes and new composition indexes\n",
    "    return notes, new_composition_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lydia/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 1998'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing mazrka11.mid\n",
      "Parsing mazrka41.mid\n",
      "Parsing mazrka03.mid\n",
      "Parsing mazrka07.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lydia/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'                                \\x82e.\\x82e.\\x82bHOPIN                                                    \\x81u\\x89~\\x95\\x91\\x8b\\xc8\\x91\\xe6\\x82R\\x94\\xd4\\x81v                 Op.34 No.2                                                for piano solo                                       ----------------------------            Roland GS                                              by MOCLIN(GBA02512)     '>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ch_wal03.mid\n",
      "Error parsing lechi4.mid: badly formatted midi bytes, got: b'RIFF*\\xa4\\x00\\x00RMIDdata\\x1e\\xa4\\x00\\x00'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lydia/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'F.F.Chopin  Nocturne No.11 in G minor Op.37-1 \\x81@'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chonoc11.mid\n",
      "Parsing ballade2.mid\n",
      "Parsing scherzo1.mid\n",
      "Parsing chop23b.mid\n",
      "Parsing mazrka18.mid\n",
      "Parsing algrcrt3.mid\n",
      "Parsing mazrka02.mid\n",
      "✅Loading training done\n"
     ]
    }
   ],
   "source": [
    "notes, new_composition_indexes = load_midi_into_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab, new_composition_indexes):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    wait = 0\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "\n",
    "        # if the ground truth index is a note/chord that belongs to a new composition\n",
    "        if (i + sequence_length) in new_composition_indexes:\n",
    "            wait = sequence_length - 1\n",
    "            continue\n",
    "        if wait != 0:\n",
    "            wait = wait - 1\n",
    "            continue\n",
    "\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input_training = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "    # normalize input\n",
    "    network_input_training = network_input_training / float(n_vocab)\n",
    "    \n",
    "    # one-hot encoding of the output\n",
    "    network_output_training = to_categorical(network_output, num_classes=n_vocab)\n",
    "\n",
    "    return network_input_training, network_output_training, network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B4',\n",
       " '4.9',\n",
       " '7',\n",
       " 'F#4',\n",
       " 'B3',\n",
       " '4.7.11',\n",
       " 'A2',\n",
       " 'D5',\n",
       " '9.0.4',\n",
       " 'D5',\n",
       " 'C5',\n",
       " '9.0.4',\n",
       " 'D3',\n",
       " '11.0.4',\n",
       " 'A4',\n",
       " '11.2.4',\n",
       " 'F#4',\n",
       " '9.0.2',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G2',\n",
       " 'C5',\n",
       " '2.7',\n",
       " 'B4',\n",
       " 'B2',\n",
       " '6.9.11.0',\n",
       " 'B2',\n",
       " '11.1',\n",
       " 'D5',\n",
       " 'B4',\n",
       " '3.6.9.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " 'G5',\n",
       " '7.11',\n",
       " 'C6',\n",
       " 'B5',\n",
       " '7.11',\n",
       " 'B5',\n",
       " '7.11',\n",
       " 'B-5',\n",
       " 'E3',\n",
       " '6.10.1',\n",
       " 'B-3',\n",
       " 'A5',\n",
       " '6.9.0',\n",
       " 'A5',\n",
       " 'E3',\n",
       " '3.6.9',\n",
       " 'E3',\n",
       " 'A5',\n",
       " '4.7',\n",
       " 'B4',\n",
       " 'B2',\n",
       " '11.0',\n",
       " '6.9.11.1',\n",
       " '11.2',\n",
       " '3.6.9.11',\n",
       " '3.6.9.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'G6',\n",
       " '6.7',\n",
       " '6.7',\n",
       " 'B3',\n",
       " 'E6',\n",
       " 'C6',\n",
       " 'B5',\n",
       " 'F#2',\n",
       " 'B-5',\n",
       " 'C#6',\n",
       " 'F#2',\n",
       " '11.1.3.4.6',\n",
       " 'G#5',\n",
       " '1.4.6',\n",
       " '6.10',\n",
       " '6.10',\n",
       " 'B2',\n",
       " '11.3',\n",
       " '6.11',\n",
       " '6.11',\n",
       " 'B4',\n",
       " 'E2',\n",
       " 'A4',\n",
       " '7.11',\n",
       " 'G3',\n",
       " 'F#4',\n",
       " '4.7.11',\n",
       " 'A2',\n",
       " '4.7.11',\n",
       " 'D5',\n",
       " '9.0.4',\n",
       " 'C5',\n",
       " '9.0.4',\n",
       " 'D3',\n",
       " '11.0.4',\n",
       " 'A4',\n",
       " '11.2.4',\n",
       " 'D3',\n",
       " 'F#4',\n",
       " 'D4',\n",
       " '9.0',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'G2',\n",
       " '2.7',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'B2',\n",
       " 'C5',\n",
       " '6.9.11.1',\n",
       " '11.2',\n",
       " '3.6.9.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " '7.11',\n",
       " 'G5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'C6',\n",
       " '11',\n",
       " 'G4',\n",
       " 'B-5',\n",
       " 'E3',\n",
       " '6.10.1',\n",
       " '6.10.1',\n",
       " 'A5',\n",
       " '6.9.0',\n",
       " 'A5',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " '3.9',\n",
       " 'A5',\n",
       " '4.7',\n",
       " 'B4',\n",
       " 'B2',\n",
       " '11.0',\n",
       " '6.9.11.1',\n",
       " '11.2',\n",
       " '6.9.11',\n",
       " 'E-5',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'G6',\n",
       " '6.7',\n",
       " '6.7.11',\n",
       " 'E6',\n",
       " 'C6',\n",
       " 'B5',\n",
       " 'C6',\n",
       " 'B-5',\n",
       " 'B2',\n",
       " 'F#5',\n",
       " '9.11.0.3',\n",
       " 'B-5',\n",
       " 'B5',\n",
       " '9.11.3',\n",
       " 'A5',\n",
       " 'B-5',\n",
       " 'G#5',\n",
       " 'A5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'F#5',\n",
       " '7.11',\n",
       " 'E5',\n",
       " '5.7',\n",
       " 'D5',\n",
       " '5.7',\n",
       " 'D5',\n",
       " 'B4',\n",
       " '2.7',\n",
       " 'A4',\n",
       " '2.5',\n",
       " 'G3',\n",
       " '9.11.0',\n",
       " 'E4',\n",
       " 'G4',\n",
       " '0.4.7',\n",
       " '0.4',\n",
       " '4.7',\n",
       " '0.4',\n",
       " 'G#3',\n",
       " 'G3',\n",
       " 'F4',\n",
       " 'D5',\n",
       " 'B4',\n",
       " '5.7.0',\n",
       " '5.7.9.0',\n",
       " '9.11',\n",
       " '0.4.7',\n",
       " 'G4',\n",
       " 'G4',\n",
       " '0.4.7',\n",
       " 'C5',\n",
       " '9.0.4',\n",
       " '2.5',\n",
       " 'A3',\n",
       " 'B4',\n",
       " '4.9',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'C5',\n",
       " 'C4',\n",
       " 'A4',\n",
       " '4.9',\n",
       " 'C4',\n",
       " 'A4',\n",
       " 'E4',\n",
       " '9.0.2.5',\n",
       " 'B4',\n",
       " 'E3',\n",
       " 'A2',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'C5',\n",
       " '9.0',\n",
       " '11',\n",
       " '8.11.3',\n",
       " '6.9',\n",
       " '9.1',\n",
       " '8.11.3',\n",
       " 'E4',\n",
       " 'G#3',\n",
       " 'E3',\n",
       " '4',\n",
       " '4',\n",
       " 'E5',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'D5',\n",
       " '5.7.11',\n",
       " '5.9',\n",
       " 'G3',\n",
       " '9.11',\n",
       " 'G3',\n",
       " '0.4',\n",
       " 'G4',\n",
       " '0.4',\n",
       " 'G3',\n",
       " '4.7',\n",
       " 'E5',\n",
       " 'C3',\n",
       " 'G#3',\n",
       " '5.7',\n",
       " 'D5',\n",
       " '5.11',\n",
       " '5.7.0',\n",
       " '5.11',\n",
       " '7.9.0',\n",
       " 'F4',\n",
       " '9.11',\n",
       " 'G4',\n",
       " '0.4.7',\n",
       " '0.4.7',\n",
       " '0',\n",
       " '7.0',\n",
       " 'E4',\n",
       " '0',\n",
       " '7.0',\n",
       " '11.0',\n",
       " '2.6',\n",
       " 'A4',\n",
       " '11.0.2.6',\n",
       " 'A4',\n",
       " 'D4',\n",
       " 'B3',\n",
       " 'G3',\n",
       " '2.7',\n",
       " '6.11.0',\n",
       " 'A4',\n",
       " '11.0.2.6.7',\n",
       " 'A4',\n",
       " 'A4',\n",
       " '7.11.0.2',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " '7.11.2',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " '0.3',\n",
       " 'G2',\n",
       " '1.4',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " '1.4',\n",
       " 'G2',\n",
       " '2.5',\n",
       " 'G2',\n",
       " '1.4',\n",
       " 'G2',\n",
       " '0.3.7',\n",
       " '10.0.3',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " 'G2',\n",
       " '7.10.0.3',\n",
       " 'G#4',\n",
       " '2.7',\n",
       " 'B3',\n",
       " '7.10.0.3',\n",
       " 'G#4',\n",
       " '10.0.3',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " '10.0.3',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " '7.11.2',\n",
       " 'G2',\n",
       " '0.3',\n",
       " 'A4',\n",
       " 'G2',\n",
       " '1.4',\n",
       " '2.5',\n",
       " 'G2',\n",
       " '2.5',\n",
       " 'G2',\n",
       " 'A4',\n",
       " '1.4',\n",
       " 'G2',\n",
       " '0.3',\n",
       " 'G2',\n",
       " '7.11.2',\n",
       " 'G2',\n",
       " '0.3.7',\n",
       " 'G#4',\n",
       " '1.4',\n",
       " 'G2',\n",
       " 'G#4',\n",
       " '2.5',\n",
       " 'G2',\n",
       " 'G2',\n",
       " 'A4',\n",
       " '1.4',\n",
       " '0.3.7',\n",
       " 'G2',\n",
       " '7.11.2',\n",
       " 'G2',\n",
       " '7.11.2',\n",
       " '0.3.7',\n",
       " 'A4',\n",
       " '1.4.7',\n",
       " '2.5.7',\n",
       " '1.4.7',\n",
       " '7.8.0.3',\n",
       " '7.11.2',\n",
       " '7.8.0.3',\n",
       " '7.8.0.3',\n",
       " '7.8.0.3',\n",
       " '7.8.0.3',\n",
       " '1.4.7.9',\n",
       " '1.4.7.9',\n",
       " '1.4.7.9',\n",
       " '10.1.4.6',\n",
       " '10.1.4.6',\n",
       " '10.1.4.6',\n",
       " '11.2.5',\n",
       " '11.3.6',\n",
       " 'B2',\n",
       " '11.3.6',\n",
       " 'B2',\n",
       " '11.4',\n",
       " 'E3',\n",
       " 'A4',\n",
       " 'E2',\n",
       " '7',\n",
       " 'B3',\n",
       " 'F#4',\n",
       " '4.7.11',\n",
       " 'A2',\n",
       " 'D5',\n",
       " '9.0.4',\n",
       " 'C5',\n",
       " '9.0.4',\n",
       " 'D3',\n",
       " '11.0',\n",
       " 'E4',\n",
       " 'A4',\n",
       " '11.2.4',\n",
       " 'F#4',\n",
       " 'D3',\n",
       " '9.0',\n",
       " 'D4',\n",
       " 'G4',\n",
       " 'G2',\n",
       " 'C5',\n",
       " '2.7',\n",
       " 'B4',\n",
       " 'B2',\n",
       " 'B2',\n",
       " '11.0',\n",
       " '6.9.11.1',\n",
       " '11.2',\n",
       " '3.6.9.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " '7.11',\n",
       " 'G5',\n",
       " 'C6',\n",
       " 'G4',\n",
       " '11',\n",
       " 'C6',\n",
       " 'E3',\n",
       " 'B-5',\n",
       " 'E3',\n",
       " '6.10.1',\n",
       " '6.10',\n",
       " 'A5',\n",
       " '6.9',\n",
       " '0.6',\n",
       " 'A5',\n",
       " 'E3',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " '3.9',\n",
       " '4.7',\n",
       " 'B4',\n",
       " 'B2',\n",
       " '11.0',\n",
       " '6.9.11.1',\n",
       " '11.2',\n",
       " '3.6.9.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'G6',\n",
       " '6.7',\n",
       " '6.7.11',\n",
       " 'E6',\n",
       " 'C6',\n",
       " 'B5',\n",
       " 'E3',\n",
       " 'B-5',\n",
       " 'B5',\n",
       " 'E3',\n",
       " '11.0.3',\n",
       " 'B-5',\n",
       " '11',\n",
       " '11.3.6',\n",
       " 'A5',\n",
       " 'G5',\n",
       " 'E3',\n",
       " 'G6',\n",
       " 'F#6',\n",
       " 'G6',\n",
       " 'B3',\n",
       " 'G4',\n",
       " 'F#6',\n",
       " 'E6',\n",
       " 'C6',\n",
       " 'B3',\n",
       " 'G4',\n",
       " 'E6',\n",
       " 'B5',\n",
       " 'E3',\n",
       " 'B-5',\n",
       " 'B5',\n",
       " '9.11.0.3',\n",
       " 'B-5',\n",
       " '9.11.3',\n",
       " 'F#5',\n",
       " 'A5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'E7',\n",
       " '0.2',\n",
       " '4.7.11',\n",
       " 'C7',\n",
       " 'B6',\n",
       " 'G6',\n",
       " 'E6',\n",
       " 'C6',\n",
       " 'B5',\n",
       " 'E3',\n",
       " 'B-5',\n",
       " 'F#5',\n",
       " 'E3',\n",
       " 'F#5',\n",
       " '11.0',\n",
       " '9.11.3',\n",
       " 'B-5',\n",
       " 'B5',\n",
       " '3.9',\n",
       " '9.11.3',\n",
       " 'B-5',\n",
       " 'G#5',\n",
       " 'A5',\n",
       " 'E3',\n",
       " 'G5',\n",
       " 'F#5',\n",
       " 'F#5',\n",
       " 'E3',\n",
       " '4.7.11',\n",
       " 'E3',\n",
       " '4.7.11',\n",
       " 'E4',\n",
       " 'A4',\n",
       " '8.1',\n",
       " 'C#5',\n",
       " '1.4.8',\n",
       " '1.4.8',\n",
       " 'E-5',\n",
       " '1.4.8',\n",
       " 'C#5',\n",
       " 'C#5',\n",
       " 'E-3',\n",
       " 'C5',\n",
       " '6.8.0',\n",
       " 'E-5',\n",
       " '6.8.0',\n",
       " 'C3',\n",
       " 'C3',\n",
       " '3.6.8',\n",
       " 'E-5',\n",
       " '3.6.8',\n",
       " 'E5',\n",
       " 'C#3',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'E5',\n",
       " '1.4.8',\n",
       " 'C#5',\n",
       " 'C#3',\n",
       " '1.4.8',\n",
       " 'E3',\n",
       " '8.1',\n",
       " 'G#5',\n",
       " 'E3',\n",
       " 'G#5',\n",
       " '8.1',\n",
       " 'A5',\n",
       " 'E-3',\n",
       " 'G#5',\n",
       " 'G5',\n",
       " '7.10.1',\n",
       " 'E-5',\n",
       " '7.10.1',\n",
       " 'E5',\n",
       " 'E-5',\n",
       " 'G#2',\n",
       " 'F#5',\n",
       " 'G#5',\n",
       " '6.8.0',\n",
       " '6.8.0',\n",
       " 'F#5',\n",
       " 'C#3',\n",
       " 'E5',\n",
       " 'C#3',\n",
       " 'E5',\n",
       " 'E-5',\n",
       " '1.4.8',\n",
       " 'C#5',\n",
       " '11.1.4.7',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'C#3',\n",
       " 'C#5',\n",
       " '1.4.8',\n",
       " 'C#5',\n",
       " 'C#3',\n",
       " '1.4.8',\n",
       " 'E-5',\n",
       " 'E-3',\n",
       " 'C#5',\n",
       " 'C5',\n",
       " '0.3.6.8',\n",
       " '6.8.0',\n",
       " 'E-3',\n",
       " 'C3',\n",
       " '3.6.8',\n",
       " 'E-5',\n",
       " '3.6.8',\n",
       " 'E5',\n",
       " 'C#3',\n",
       " 'E-5',\n",
       " 'C#3',\n",
       " 'C#5',\n",
       " '4.8',\n",
       " 'E5',\n",
       " '4.6.10',\n",
       " 'B2',\n",
       " 'B4',\n",
       " 'B2',\n",
       " 'B4',\n",
       " '4.8.11',\n",
       " 'B5',\n",
       " '4.8.11',\n",
       " 'C#6',\n",
       " 'B2',\n",
       " 'B5',\n",
       " 'B-5',\n",
       " 'F#5',\n",
       " '1.4.6',\n",
       " 'B2',\n",
       " '1.4.6',\n",
       " 'G#5',\n",
       " 'B1',\n",
       " 'A5',\n",
       " '11.3.6',\n",
       " 'B5',\n",
       " '11.3.6',\n",
       " 'B5',\n",
       " 'A5',\n",
       " 'E2',\n",
       " 'G#5',\n",
       " 'E-5',\n",
       " '4.6',\n",
       " '4.8.11',\n",
       " 'E5',\n",
       " 'E-5',\n",
       " 'E5',\n",
       " 'F#5',\n",
       " '8.0',\n",
       " '3.6.8',\n",
       " 'E-5',\n",
       " 'G#5',\n",
       " 'F#5',\n",
       " 'C#3',\n",
       " 'E5',\n",
       " 'C#3',\n",
       " 'E5',\n",
       " '0.1.4.8',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'B4',\n",
       " 'C#2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " '1.4.7.9',\n",
       " 'A4',\n",
       " '1.4.7',\n",
       " 'G#4',\n",
       " 'C#3',\n",
       " 'C#5',\n",
       " '1.3.4.8',\n",
       " 'E5',\n",
       " 'G#5',\n",
       " 'C#6',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '3.8',\n",
       " 'E-5',\n",
       " 'G#5',\n",
       " 'F#5',\n",
       " '1.4',\n",
       " '0.4.8',\n",
       " 'E-5',\n",
       " 'E-5',\n",
       " '8.10.1.4',\n",
       " 'B-4',\n",
       " 'E-2',\n",
       " 'E-4',\n",
       " '3.4',\n",
       " 'E4',\n",
       " '11.3',\n",
       " 'D4',\n",
       " '3',\n",
       " '1.3.7',\n",
       " 'B4',\n",
       " '8',\n",
       " 'G#3',\n",
       " 'D3',\n",
       " 'B3',\n",
       " 'G#4',\n",
       " 'E3',\n",
       " 'E-3',\n",
       " 'B2',\n",
       " 'G#2',\n",
       " 'G#5',\n",
       " '0.3',\n",
       " 'F#4',\n",
       " 'E-5',\n",
       " 'G#5',\n",
       " 'F#5',\n",
       " '1.4',\n",
       " '1.4',\n",
       " '0.1.4.8',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'B4',\n",
       " 'C#2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " '4.7.9',\n",
       " 'A4',\n",
       " '4.7',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'C#3',\n",
       " 'C#5',\n",
       " '3.4.8',\n",
       " 'E5',\n",
       " 'C#3',\n",
       " 'G#5',\n",
       " 'C#6',\n",
       " '8.0',\n",
       " '3.8',\n",
       " 'E-5',\n",
       " 'B2',\n",
       " 'G#5',\n",
       " 'G5',\n",
       " 'B-2',\n",
       " 'F#5',\n",
       " 'E5',\n",
       " '0.1.4',\n",
       " 'E-5',\n",
       " 'A2',\n",
       " 'C#5',\n",
       " 'E-5',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'G#2',\n",
       " '8.9',\n",
       " 'A4',\n",
       " '4.8',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " '6.8.0',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'C#5',\n",
       " 'C#3',\n",
       " 'C#4',\n",
       " '4.8',\n",
       " 'C#5',\n",
       " 'B3',\n",
       " 'A3',\n",
       " 'C#4',\n",
       " 'A3',\n",
       " '3.8',\n",
       " 'G3',\n",
       " 'E-4',\n",
       " '0.3.6',\n",
       " 'G#3',\n",
       " 'G#3',\n",
       " '1.5',\n",
       " '3.8',\n",
       " 'C4',\n",
       " 'G#4',\n",
       " '3.8',\n",
       " 'C4',\n",
       " '6.8',\n",
       " '1.5',\n",
       " 'G#3',\n",
       " 'F#2',\n",
       " 'E-4',\n",
       " 'B-3',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'E-4',\n",
       " '5.8.0',\n",
       " 'G#2',\n",
       " 'F#2',\n",
       " 'F#3',\n",
       " 'E-4',\n",
       " '3.5',\n",
       " 'B-2',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'D4',\n",
       " 'G#3',\n",
       " '0.3',\n",
       " '1.5',\n",
       " 'C#4',\n",
       " 'E-4',\n",
       " '3.8',\n",
       " 'E-4',\n",
       " 'G#3',\n",
       " 'C#4',\n",
       " '3.8',\n",
       " 'E-4',\n",
       " '3.6.8',\n",
       " 'F4',\n",
       " '1.5.8',\n",
       " '3.8',\n",
       " 'C4',\n",
       " 'G#4',\n",
       " 'B-4',\n",
       " '6.8',\n",
       " '6.8',\n",
       " '3.8',\n",
       " 'C#4',\n",
       " '1.5',\n",
       " 'G#3',\n",
       " 'B-3',\n",
       " 'F#2',\n",
       " 'E-4',\n",
       " 'C#5',\n",
       " '3.6',\n",
       " '0.5',\n",
       " '5.8',\n",
       " '3.5',\n",
       " 'E-4',\n",
       " 'B-2',\n",
       " 'F#3',\n",
       " 'D4',\n",
       " '0.3',\n",
       " 'G#3',\n",
       " '1.5',\n",
       " 'C#2',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " '5.8.11',\n",
       " 'E-4',\n",
       " '1.6',\n",
       " 'B-4',\n",
       " 'B-3',\n",
       " 'C#5',\n",
       " 'C#3',\n",
       " 'B4',\n",
       " '3.5.8.11',\n",
       " '10.1',\n",
       " 'C#3',\n",
       " '3.5.8.11',\n",
       " 'F#4',\n",
       " 'G#4',\n",
       " 'C#3',\n",
       " 'E-5',\n",
       " '3.5.8.11',\n",
       " '6.10.1',\n",
       " '8.10',\n",
       " '3.6.8.11',\n",
       " '3.6.8.11',\n",
       " 'G4',\n",
       " '5.8.11.1',\n",
       " '6.10',\n",
       " 'C#2',\n",
       " 'G#4',\n",
       " 'E-4',\n",
       " '5.8.11',\n",
       " 'C#2',\n",
       " 'E-4',\n",
       " '5.8.11',\n",
       " '6.10.1',\n",
       " 'B-3',\n",
       " 'C#5',\n",
       " 'C#3',\n",
       " 'B4',\n",
       " '5.8.11',\n",
       " 'C#4',\n",
       " 'F#4',\n",
       " '6.10',\n",
       " 'F#4',\n",
       " 'C#3',\n",
       " 'C#4',\n",
       " '6.10',\n",
       " 'E-5',\n",
       " 'E-3',\n",
       " 'C#5',\n",
       " 'E-4',\n",
       " '7.10.1',\n",
       " 'G#4',\n",
       " '8.11',\n",
       " 'E5',\n",
       " 'E3',\n",
       " 'E5',\n",
       " 'G#4',\n",
       " 'E3',\n",
       " 'D5',\n",
       " 'D5',\n",
       " '11.4',\n",
       " 'G#4',\n",
       " '11.4',\n",
       " 'G#4',\n",
       " 'D5',\n",
       " 'G#4',\n",
       " 'A2',\n",
       " 'G4',\n",
       " 'C#5',\n",
       " '4.7.9',\n",
       " '3.7.9',\n",
       " 'E-5',\n",
       " 'E-5',\n",
       " '8.1',\n",
       " 'C5',\n",
       " '3.6.8',\n",
       " 'E-5',\n",
       " '6.8.11.1',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'G#4',\n",
       " 'E-5',\n",
       " '6.8.0',\n",
       " '6.8.0',\n",
       " 'E5',\n",
       " '1.3',\n",
       " 'C#5',\n",
       " '1.4.8',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'B4',\n",
       " 'A4',\n",
       " 'E2',\n",
       " 'G#4',\n",
       " 'G#5',\n",
       " '8.1',\n",
       " '8.1',\n",
       " 'A5',\n",
       " 'G#5',\n",
       " 'A5',\n",
       " '3.8',\n",
       " 'G5',\n",
       " 'E-5',\n",
       " '10.1.3',\n",
       " '1.3.7',\n",
       " 'E5',\n",
       " '6.8',\n",
       " '6.8',\n",
       " 'G#5',\n",
       " '8.0.3',\n",
       " '6.8.0',\n",
       " 'F#5',\n",
       " 'C#2',\n",
       " 'E5',\n",
       " 'E-5',\n",
       " '1.4.8',\n",
       " 'C#5',\n",
       " '11.1.4.7',\n",
       " 'A4',\n",
       " '8.1',\n",
       " 'C#5',\n",
       " '1.4.8',\n",
       " '1.4.8',\n",
       " 'E-5',\n",
       " 'E-3',\n",
       " 'C#5',\n",
       " 'E-3',\n",
       " 'C#5',\n",
       " 'C5',\n",
       " '6.8.0',\n",
       " 'E-5',\n",
       " '6.8.11.0',\n",
       " 'A4',\n",
       " '8.0',\n",
       " 'E-5',\n",
       " '3.6.8',\n",
       " 'E-5',\n",
       " '3.6.8',\n",
       " 'E5',\n",
       " 'E-5',\n",
       " 'B2',\n",
       " 'C#5',\n",
       " 'F5',\n",
       " '8.1',\n",
       " '8.1',\n",
       " 'F5',\n",
       " 'B2',\n",
       " 'B-2',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " '1.6',\n",
       " 'F#5',\n",
       " 'E-5',\n",
       " 'A2',\n",
       " 'C#5',\n",
       " '1.4',\n",
       " 'A2',\n",
       " 'C#5',\n",
       " '7.9',\n",
       " 'G5',\n",
       " 'E-5',\n",
       " 'C#5',\n",
       " 'C#6',\n",
       " '1.4',\n",
       " '7.9',\n",
       " 'C#6',\n",
       " 'G#4',\n",
       " 'G#2',\n",
       " '8.9',\n",
       " '8.9.1.4',\n",
       " 'G#4',\n",
       " 'G4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " '6.8.0',\n",
       " 'E5',\n",
       " 'C#2',\n",
       " 'C#5',\n",
       " 'C#4',\n",
       " '4.8',\n",
       " 'C#5',\n",
       " '4.8',\n",
       " 'C#5',\n",
       " 'E3',\n",
       " '8.1',\n",
       " 'G#5',\n",
       " '8.1',\n",
       " 'A5',\n",
       " 'G#5',\n",
       " 'E-3',\n",
       " 'G5',\n",
       " 'E-5',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vocabulary (unique notes)\n",
    "n_vocab = len(set(notes))\n",
    "n_vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input_training, network_output_training, network_output_training_to_plot = prepare_sequences(notes, n_vocab, new_composition_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18397\n"
     ]
    }
   ],
   "source": [
    "print(len(network_input_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    int(n_vocab),\n",
    "    input_shape=(network_input_training.shape[1], network_input_training.shape[2]),\n",
    "    return_sequences=True,\n",
    "))\n",
    "\n",
    "\n",
    "model.add(LSTM(\n",
    "        n_vocab,\n",
    "        return_sequences=True,\n",
    "        recurrent_dropout=0.3,\n",
    "    ))\n",
    "\n",
    "model.add(LSTM(int(n_vocab/2)))\n",
    "\n",
    "\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 569)          1299596   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 569)          2592364   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 284)               970144    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 284)               1136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 284)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 569)               162165    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 569)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5025405 (19.17 MB)\n",
      "Trainable params: 5024837 (19.17 MB)\n",
      "Non-trainable params: 568 (2.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../checkpoint_lstm\", exist_ok=True)\n",
    "file_path = \"../../checkpoint_lstm/best_weigths.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    file_path,\n",
    "    monitor='accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 15/230 [>.............................] - ETA: 4:12 - loss: 5.8924 - accuracy: 0.0312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m callbacks_list \u001b[39m=\u001b[39m [checkpoint,es]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(network_input_training, network_output_training, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m ,callbacks\u001b[39m=\u001b[39;49mcallbacks_list, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks_list = [checkpoint,es]\n",
    "\n",
    "history = model.fit(network_input_training, network_output_training, epochs=200, batch_size=64 ,callbacks=callbacks_list, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the notes used to train the model\n",
    "with open('../../data_vocab/notes.pkl', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# Get all pitch names\n",
    "n_vocab = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the possible sequences to start from\n",
    "\n",
    "# map between notes and integers and back\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "sequence_length = 100\n",
    "network_input = []\n",
    "output = []\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    output.append(note_to_int[sequence_out])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "# normalize input\n",
    "normalized_input = normalized_input / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '../../checkpoint_lstm/best_weigths.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m\"\u001b[39;49m\u001b[39m../../checkpoint_lstm/best_weigths.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/ChopAI/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../../checkpoint_lstm/best_weigths.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"../../checkpoint_lstm/best_weigths.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 22\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m start \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(network_input)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m int_to_note \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((number, note) \u001b[39mfor\u001b[39;00m number, note \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pitchnames))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pattern \u001b[39m=\u001b[39m network_input[\u001b[39m25345\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m prediction_output \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#save a probability here, useful just for the documentation\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "  # pick a random sequence from the input as a starting point for the prediction\n",
    "  start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "  int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "  pattern = network_input[25345]\n",
    "  prediction_output = []\n",
    "\n",
    "  #save a probability here, useful just for the documentation\n",
    "  probability_distribution = None\n",
    "\n",
    "  id_notes = np.arange(0, n_vocab)\n",
    "  # generate 500 notes\n",
    "  for note_index in range(500):\n",
    "      prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "      prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "      prediction_probabilities = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "      #for the documentation\n",
    "      probability_distribution = prediction_probabilities[0]\n",
    "\n",
    "      index = np.random.choice(id_notes,1, p = prediction_probabilities[0])\n",
    "      #print(index)\n",
    "      result = int_to_note[index[0]]\n",
    "      prediction_output.append(result)\n",
    "\n",
    "      pattern.append(index[0])\n",
    "      pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m output_notes \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# create note and chord objects based on the values generated by the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m pattern \u001b[39min\u001b[39;00m prediction_output:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# pattern is a chord\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m pattern) \u001b[39mor\u001b[39;00m pattern\u001b[39m.\u001b[39misdigit():\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         notes_in_chord \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction_output' is not defined"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "os.makedirs(\"../../generated_music_from_lstm\", exist_ok=True)\n",
    "\n",
    "midi_stream.write('midi', fp='../../generated_music_from_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probability_distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m numpy\u001b[39m.\u001b[39mmax(probability_distribution)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probability_distribution' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probability_distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb Cell 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m figure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m10\u001b[39m), dpi\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(probability_distribution)  \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mProbability\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lydia/code/lydia-bellahouel/ChopAI/ChopAI/ml_logic/lstm_v2.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mData\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probability_distribution' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(15, 10), dpi=80)\n",
    "\n",
    "plt.plot(probability_distribution)  \n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChopAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
